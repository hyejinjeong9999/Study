# 1. 하둡

* 빅데이터 저장 처리 시스템

* Single node : 1개 컴퓨터 (vm)로 운영
  * 하둡의 특성(분산처리시스템)을 잘 활용하지 못한 경우
* Multi clustering node : 여러대 컴퓨터로 운영
  * 우리는 4개의 vm으로 만들 예정 

#### 빅데이터의 3V

1. volume : 데이터 생성 주기가 빠르다 
2. velocity : 저장, 처리 속도가 빠르다
3. variety : 각종 형태를 담는다 : 비정형 데이터
   * (ex sns에 저장되는 데이터는 이미지 등 다양하다)
   * oracle의 데이터는 정형데이터다 

#### 빅데이터 처리과정

데이터소스 - 수집 - 저장 - 처리 - 분석 - 표현

**서버** : 데이터 소스, 수집 

**하둡** : 저장,처리용

**R** : 분석 /표현용



## 환경설정하기

1. master 생성
2. 환경설정 
3. slave1,2,3 생성 (master 복제)
4. 하둡설치
5. 환경설정
6. 실행



### 1. Master 생성

* master(대장컴퓨터) : 나머지를 연결하는 용도
* 파일 위치 : hadoop - master
* 수정할 정보

![image-20200224092550506](C:\Users\student\Desktop\Study\Study\md_img\image-20200224092550506.png)

> ***프로세스란 ?***
>
> 작업관리자 보면  코어 : 4  논리프로세서 : 8 뜸
>
> 물리적인 프로세스 : 4
>
> 멀티쓰레드방식이기 때문에 논리 프로세서가 8개까지 가능한 것



#### play virtual muchin

* centos 7 설치
* 언어 : 한국어 
* 키보드 : 영어 (미국), 한국어
* SW 선택 : 개발 및 창조를 위한 워크스테이션
* 설치대상
* 네트워크 설정 : 20g / 파티션을 선택합니다
* 표준파티션 
* swap : 2g , / : t설정x
* 네트워크 및 호스트 이름 : 
  * Ethernet(eno1677736) 켬
* 루트암호 : password
* 사용자 hadoop / hadoop
* 설치 후 라이센스 동의
* kdump 활설화 비동의

#### root 로그인

* root 로그인
* 알림 끔
* 디스플레이설정
* 전원 대기모드 안함

### 2. 환경설정

* 프로그램  - 소프트웨어 - 소프트웨어 : 최신패키지만 (x). 전용패키지만 (x), 소프트웨어 공급원 :업데이트 하지 않기

* yum 자동 업데이트 방지

  * 네트워크 설정파일 열기

  * ````
    [root@localhost ~]# gedit /etc/sysconfig/network-scripts/ifcfg-eno16777736 
    ````

    ````
    HWADDR="00:0C:29:72:6A:63"
    TYPE="Ethernet"
    BOOTPROTO="~~"  --------->none으로 변경
    DEFROUTE="yes"
    PEERDNS="yes"
    PEERROUTES="yes"
    IPV4_FAILURE_FATAL="no"
    IPV6INIT="yes"
    IPV6_AUTOCONF="yes"
    IPV6_DEFROUTE="yes"
    IPV6_PEERDNS="yes"
    IPV6_PEERROUTES="yes"
    IPV6_FAILURE_FATAL="no"
    NAME="eno16777736"
    UUID="6b97334a-1d57-4f94-bc9a-50c8641a853a"
    ONBOOT="yes"
    ------추가-------
    IPADDR=192.168.111.110
    NETMASK=255.255.255.0
    GATEWAY=192.168.111.2
    DNS1=192.168.111.2
    ````

    ````
    [root@localhost ~]# systemctl restart network
    재시작
    ````

    ```
    [root@localhost ~]# ifconfig 
    eno16777736: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
            inet 192.168.111.110  netmask 255.255.255.0  broadcast 192.168.111.255 ----> 바뀐거 확인
            ether 00:0c:29:72:6a:63  txqueuelen 1000  (Ethernet)
            RX packets 20207  bytes 29448503 (28.0 MiB)
            RX errors 0  dropped 0  overruns 0  frame 0
            TX packets 7334  bytes 450733 (440.1 KiB)
            TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
    
    ```

    ````
    [root@localhost ~]# gedit /etc/yum.repos.d/CentOS-Base.repo 
    ````

    ````
     주석처리
    #released updates 
    #[updates]
    #name=CentOS-$releasever - Updates
    #mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=updates
    #baseurl=http://mirror.centos.org/centos/$releasever/updates/$basearch/
    #gpgcheck=1
    #gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7
    ````

    ````
    [root@localhost ~]# gedit /etc/yum.repos.d/CentOS-Sources.repo
    ````

    ````
    주석
    #released updates 
    #[updates-source]
    #name=CentOS-$releasever - Updates Sources
    #baseurl=http://vault.centos.org/centos/$releasever/updates/Source/
    #gpgcheck=1
    #enabled=0
    #gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7
    ````

    ````
    지금 설정 백업
    [root@localhost ~]# mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak
    ````

    ````
    [root@localhost ~]# cd /etc/yum.repos.d/
    [root@localhost yum.repos.d]# wget http://download.hanbit.co.kr/centos/7/CentOS-Base.repo--2020-02-24 
    
    10:38:29--  http://download.hanbit.co.kr/centos/7/CentOS-Base.repo
    Resolving download.hanbit.co.kr (download.hanbit.co.kr)... 218.38.58.196
    Connecting to download.hanbit.co.kr (download.hanbit.co.kr)|218.38.58.196|:80... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 218 [text/plain]
    Saving to: ‘CentOS-Base.repo’
    
    100%[=========================================================>] 218         --.-K/s   in 0s      
    
    2020-02-24 10:38:29 (58.6 MB/s) - ‘CentOS-Base.repo’ saved [218/218]
    
    
    [root@localhost yum.repos.d]# rm -f *.repo~
    [root@localhost yum.repos.d]# yum c
    check         check-update  clean         
    [root@localhost yum.repos.d]# yum clean all 
    Loaded plugins: fastestmirror, langpacks
    Cleaning repos: base extras
    Cleaning up everything
    
    ````

* selinux 방지

  ````
  [root@localhost yum.repos.d]# gedit /etc/sysconfig/selinux 
  ````

  ````
  
  # This file controls the state of SELinux on the system.
  # SELINUX= can take one of these three values:
  #     enforcing - SELinux security policy is enforced.
  #     permissive - SELinux prints warnings instead of enforcing.
  #     disabled - No SELinux policy is loaded.
  SELINUX=enforcing -------> disabled로 수정
  # SELINUXTYPE= can take one of these two values:
  #     targeted - Targeted processes are protected,
  #     minimum - Modification of targeted policy. Only selected processes are protected. 
  #     mls - Multi Level Security protection.
  SELINUXTYPE=targeted 
  
  ````

* 방화벽 해제

  ````
  [root@localhost yum.repos.d]# systemctl status firewalld
  firewalld.service - firewalld - dynamic firewall daemon
     Loaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled)
     Active: active (running) since 월 2020-02-24 09:57:12 KST; 54min ago
   Main PID: 754 (firewalld)
     CGroup: /system.slice/firewalld.service
             └─754 /usr/bin/python -Es /usr/sbin/firewalld --nofork --nopid
  
   2월 24 09:57:12 localhost.localdomain systemd[1]: Started firewalld - dynamic firewall daemon.
   2월 24 10:25:01 localhost.localdomain firewalld[754]: 2020-02-24 10:25:01 ERROR: UNKNOWN_INT...36
  Hint: Some lines were ellipsized, use -l to show in full.
  
  active인거 확인
  ````

  ````
  [root@localhost yum.repos.d]# systemctl stop firewalld
  
  [root@localhost yum.repos.d]# systemctl disable firewalld
  rm '/etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service'
  rm '/etc/systemd/system/basic.target.wants/firewalld.service'
  
  ````

  ````
  [root@localhost yum.repos.d]# systemctl restart network
  네트워크 재시작
  ````

#### jdk 다운

````
[root@localhost ~]# yum remove java
````

````
[root@localhost local]# mv /root/다운로드/jdk-8u241-linux-x64.tar.gz .
현재폴더로 파일 옮기기
[root@localhost local]# ls
bin  etc  games  include  jdk-8u241-linux-x64.tar.gz  lib  lib64  libexec  sbin  share  src

[root@localhost local]# tar xvfz jdk-8u241-linux-x64.tar.gz 

[root@localhost local]# ls
bin  games    jdk-8u241-linux-x64.tar.gz  lib    libexec  share
etc  include  jdk1.8.0_241                lib64  sbin     src

````

````
[root@localhost local]# ln -s jdk1.8.0_241 jdk1.8
[root@localhost local]# ls -l
합계 189992
drwxr-xr-x. 2 root  root          6  6월 10  2014 bin
drwxr-xr-x. 2 root  root          6  6월 10  2014 etc
drwxr-xr-x. 2 root  root          6  6월 10  2014 games
drwxr-xr-x. 2 root  root          6  6월 10  2014 include
-rwxrw-rw-. 1 root  root  194545143  2월 11 15:24 jdk-8u241-linux-x64.tar.gz
lrwxrwxrwx. 1 root  root         12  2월 24 11:01 jdk1.8 -> jdk1.8.0_241
-> 링크 하나 만들어줌
drwxr-xr-x. 7 10143 10143      4096 12월 11 19:39 jdk1.8.0_241
drwxr-xr-x. 2 root  root          6  6월 10  2014 lib
drwxr-xr-x. 2 root  root          6  6월 10  2014 lib64
drwxr-xr-x. 2 root  root          6  6월 10  2014 libexec
drwxr-xr-x. 2 root  root          6  6월 10  2014 sbin
drwxr-xr-x. 5 root  root         46  2월 24  2020 share
drwxr-xr-x. 2 root  root          6  6월 10  2014 src

````

````
[root@localhost local]# gedit /etc/profile
````

````
내용추가
export JAVA_HOME=/usr/local/jdk1.8
export PATH=$JAVA_HOME/bin:$PATH
$PATH : 기존path에 추가

[root@localhost local]# source /etc/profile
변경사항 반영

````

````
path 잘 설정되어잇는지 확인
[root@localhost ~]# java -version
java version "1.8.0_241"
Java(TM) SE Runtime Environment (build 1.8.0_241-b07)
Java HotSpot(TM) 64-Bit Server VM (build 25.241-b07, mixed mode)


경로명 확인
[root@localhost ~]# echo $PATH
/usr/local/jdk1.8/bin:/usr/local/bin:/usr/local/sbin:/usr/bin:/usr/sbin:/bin:/sbin:/root/bin


````

#### hostms네임 수정

* 여러대의컴퓨터를 원활하게 소통하기 위해
  * localhost -> master 로 변경

````
[root@localhost ~]# hostname
localhost.localdomain
[root@localhost ~]# hostnamectl set-hostname master
[root@localhost ~]# hostname
master
````

* vm1 하나 만든 후 2,3,4는 복사
* 각자의 네트워크로 연결 

### 3. slave 1,2,3 복제

루트의 경우 : /root/다운로드/*

사용자계정의 경우 : /home/사용자명디렉토리/다운로드/*

````
사용자 계정 디렉토리 확인하기
[hadoop@localhost ~]$ pwd
/home/hadoop
````



기초 설정이 끝났으면 c드라이브에 있는 master 폴더를 3개 복사한 후 각각 slave 1,2,3으로 지정한다



* 전에 만들어 놓은 vm1 목록에서 삭제하기
  * remove from the library
  * 만약 다시 추가 하고 싶으면 ==open a virtual Machine==

* Open a virtual Machine으로 파일 열기

  * Edit - Options - virtual machine name : slave1
  * Edit - Hardware -Network Adapter - Advanced -  MAC Address - Generate
    * slave1 : 00:50:56:23:B7:62
    * slave2 : 00:50:56:2C:05:6A
    * slave3 : 00:50:56:29:0E:8B

* 실행후 ==I Moved It== 선택

* root계정으로 로그인

* 터미널 실행

  ````
  [root@master ~]# gedit /etc/sysconfig/network-scripts/ifcfg-eno16777736
  
  ````

  ````
  HWADDR="00:0C:29:72:6A:63"  -----> HW 주소 : 각 MAC Adress로 붙여넣기
  .TYPE="Ethernet"
  BOOTPROTO="none"
  DEFROUTE="yes"
  PEERDNS="yes"
  PEERROUTES="yes"
  IPV4_FAILURE_FATAL="no"
  IPV6INIT="yes"
  IPV6_AUTOCONF="yes"
  IPV6_DEFROUTE="yes"
  IPV6_PEERDNS="yes"
  IPV6_PEERROUTES="yes"
  IPV6_FAILURE_FATAL="no"
  NAME="eno16777736"
  UUID="6b97334a-1d57-4f94-bc9a-50c8641a853a"
  ONBOOT="yes"
  IPADDR=192.168.111.110   -> PC끼리 식별하는 주소 : 
  slave1 : 192.168.111.130 으로 바꾸기
  slave2 : 192.168.111.140 으로 바꾸기
  slave2 : 192.168.111.150 으로 바꾸기
  NETMASK=255.255.255.0
  GATEWAY=192.168.111.2
  DNS1=192.168.111.2
  ````

  호스트네임 변경

  ````
  [root@master ~]# hostname
  master
  [root@master ~]# hostnamectl set-hostname slave1
  [root@master ~]# hostname
  slave1
  [root@master ~]# systemctl restart network
  [root@master ~]# reboot
  ````

  ## 	==3번 반복하면 완료!!==

#### 인식설정

* 우린 친구야 알려주기

````
[root@master ~]# gedit /etc/hosts

````

````
192.168.111.110 master
192.168.111.130 slave1
192.168.111.140 slave2
192.168.111.150 slave3

````

#### 			==4번 반복하면 완료!!==

* 확인

````
[root@master ~]# ping slave1
PING slave1 (192.168.111.130) 56(84) bytes of data.
64 bytes from slave1 (192.168.111.130): icmp_seq=1 ttl=64 time=0.573 ms

[root@master ~]# ping slave2
PING slave2 (192.168.111.140) 56(84) bytes of data.


[root@master ~]# ping slave3
PING slave3 (192.168.111.150) 56(84) bytes of data.

````



* ssh slave1

  * 원격으로 slqve1접속 

  ````
  [root@master ~]# ssh slave1
  The authenticity of host 'slave1 (192.168.111.130)' can't be established.
  ECDSA key fingerprint is fb:57:5a:60:ab:11:eb:84:de:12:2a:a8:60:77:93:d5.
  Are you sure you want to continue connecting (yes/no)? y
  Please type 'yes' or 'no': yes
  Warning: Permanently added 'slave1,192.168.111.130' (ECDSA) to the list of known hosts.
  root@slave1's password: 
  Last login: Mon Feb 24 13:45:05 2020
  
  [root@slave1 ~]# who
  root     :0           2020-02-24 13:45 (:0)
  root     pts/0        2020-02-24 13:47 (:0)
  root     pts/1        2020-02-24 13:57 (master)
  [root@slave1 ~]# exit
  logout
  Connection to slave1 closed.
  [root@master ~]# 
  
  ````

  * slave면서 master인것을 알 수 있다
  * exit 하면 나가짐

#### ssh key 방식

* 공인인증서와 같은 방식
* 내가 키 가지고있고 상대방이 키2를 가지고 있어서 그 둘을 조합해서 인증하는 방식
* Master -hadoop계정에서
* 키 생성

````
[hadoop@master ~]$ ssh-keygen -t rsa
rsa타입의 방식으로 ssh-keygen을 생성하겠다
````

* 키 분배

````
[hadoop@master ~]$ ssh-keygen -t rsa
Generating public/private rsa key pair.
Enter file in which to save the key (/home/hadoop/.ssh/id_rsa): 
Created directory '/home/hadoop/.ssh'.
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in /home/hadoop/.ssh/id_rsa.
Your public key has been saved in /home/hadoop/.ssh/id_rsa.pub.
The key fingerprint is:
7e:07:d2:ef:1c:d4:37:fd:c4:43:64:a6:1f:26:52:b9 hadoop@master
The key's randomart image is:
+--[ RSA 2048]----+
|             ..+ |
|            ..=  |
|           . o.+ |
|         .  .E=.o|
|        S o . .+=|
|       . . +   o+|
|        . . +   .|
|         . + .   |
|            o    |
+-----------------+
[hadoop@master ~]$ ssh-copy-id -i /home/hadoop/.ssh/id_rsa hadoop@slave1
The authenticity of host 'slave1 (192.168.111.130)' can't be established.
ECDSA key fingerprint is fb:57:5a:60:ab:11:eb:84:de:12:2a:a8:60:77:93:d5.
Are you sure you want to continue connecting (yes/no)? yes
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
hadoop@slave1's password: 

Number of key(s) added: 1

Now try logging into the machine, with:   "ssh 'hadoop@slave1'"
and check to make sure that only the key(s) you wanted were added.



````

````
[hadoop@master ~]$ ssh hadoop@slave1
Last login: Mon Feb 24 11:22:15 2020
이제 slave1 - hadoop에 비밀번호 없이 접근 가능
````

#### 		==3번 반복하면 완료!!== 



### 4. hadoop 설치

#### 파일 옮겨넣기

````
[hadoop@master ~]$ pwd
/home/hadoop
[hadoop@master ~]$ mv 다운로드/hadoop-1.2.1.tar.gz .
[hadoop@master ~]$ ls
hadoop-1.2.1.tar.gz  공개  다운로드  문서  바탕화면  비디오  사진  서식  음악

[hadoop@master ~]$ tar xvfz hadoop-1.2.1.tar.gz 

압축풀림

[hadoop@master ~]$ ls
hadoop-1.2.1         공개      문서      비디오  서식
hadoop-1.2.1.tar.gz  다운로드  바탕화면  사진    음악


````



### 5. hadoop설정

hadoop - conf 폴더에서 설정 

````
[hadoop@master conf]$ gedit hadoop-env.sh
---편집창---
# The java implementation to use.  Required.
export JAVA_HOME=/usr/local/jdk1.8
 주석해제후 값 변경
````

````
[hadoop@master conf]$ gedit masters 
----편집창----
localhost를
slave1으로 변경
````

* master에 문제생기면 slave1이 역할을 수행

````
[hadoop@master conf]$ gedit slaves 
----편집창-----
slave1
slave2
slave3
를 입력
````

* 디렉토리 생성 (hadoop-data)

````
[hadoop@master conf]$ mkdir /home/hadoop/hadoop-data

[hadoop@master conf]$ cd /home/hadoop/
[hadoop@master ~]$ ls
hadoop-1.2.1         hadoop-data  다운로드  바탕화면  사진  음악
hadoop-1.2.1.tar.gz  공개         문서      비디오    서식

````





````
[hadoop@master conf]$ gedit core-site.xml 
----입력창----
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

	<configuration>
  	  <property>
    	    <name>fs.default.name</name>
            <value>hdfs://master:9000</value>
          </property>
          <property>
            <name>hadoop.tmp.dir</name>
            <value>/home/hadoop/hadoop-data/</value>
          </property>
</configuration>

````



```
oop@master conf]$ gedit hdfs-site.xml 
----입력창---
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

	<configuration>
  	  <property>
    	    <name>dfs.replication</name>
     	    <value>3</value>
  	  </property>
  	  <property>
    	    <name>dfs.http.address</name>
    	    <value>master:50070</value>
  	  </property>
  	  <property>
    	    <name>dfs.secondary.http.address</name>
    	    <value>slave1:50090</value>
  	  </property>
</configuration>
```



````
[hadoop@master conf]$ gedit mapred-site.xml
---입력창---
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

	<configuration>
  	  <property>
   	    <name>mapred.job.tracker</name>
   	    <value>master:9001</value>
  	  </property>
</configuration>
````



#### 파일 복사

* scp  : 다른 프로토콜로

````
[hadoop@master conf]$ scp hadoop-env.sh hadoop@slave1:/home/hadoop/hadoop-1.2.1/conf
hadoop-env.sh                                 100% 2430     2.4KB/s   00:00    

[hadoop@master conf]$ scp *-site.xml hadoop@slave1:/home/hadoop/hadoop-1.2.1/conf
core-site.xml                                 100%  437     0.4KB/s   00:00    
hdfs-site.xml                                 100%  504     0.5KB/s   00:00    
mapred-site.xml                               100%  286     0.3KB/s   00:00    

````



````
[hadoop@master conf]$ gedit /home/hadoop/.bash_profile 

export PATH
export HADOOP_HOME=/home/hadoop/hadoop-1.2.1
export HADOOP_HOME_WARN_SURPRESS="TRUE"
PATH=$HADOOP_HOME/bin:$PATH
추가

[hadoop@master conf]$ source /home/hadoop/.bash_profile
값 저장

하둡 경로 잘 설정 되었는지 확인
[hadoop@master conf]$ echo $PATH
/home/hadoop/hadoop-1.2.1/bin:/usr/local/jdk1.8/bin:/usr/local/bin:/usr/local/sbin:/usr/bin:/usr/sbin:/bin:/sbin:/home/hadoop/.local/bin:/home/hadoop/bin:/home/hadoop/.local/bin:/home/hadoop/bin

[hadoop@master conf]$ hadoop namenode -format

하둡 실행
[hadoop@master conf]$ start-all.sh

자바 프로세서어떤게 떳는지 확인
[hadoop@master conf]$ jps
10544 NameNode
10856 Jps
10718 JobTracker

[hadoop@slave1 ~]$ jps
11010 Jps
10709 SecondaryNameNode
10598 DataNode
10828 TaskTracker

[hadoop@slave2 ~]$ jps
9725 DataNode
9981 Jps
9838 TaskTracker

[hadoop@slave3 ~]$ jps
9744 TaskTracker
9890 Jps
9620 DataNode


````



하둡 종료

````
[hadoop@master conf]$ stop-all.sh 
Warning: $HADOOP_HOME is deprecated.

stopping jobtracker
slave3: stopping tasktracker
slave2: stopping tasktracker
slave1: stopping tasktracker
stopping namenode
slave3: stopping datanode
slave1: stopping datanode
slave2: stopping datanode
slave1: stopping secondarynamenode

````









